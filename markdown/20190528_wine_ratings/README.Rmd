---
output: github_document
---

# Set Up

We are going to have to load in a few libraries with R's native command `library`.

## Packages for Part One

In part one of our analysis, the `tidyverse` will be used for our data import, data manipulation, and visualization.

```{r load-packages-1}
library(tidyverse) # ggplot, tibble, tidyr, readr, purrr, dplyr, stringr, forcats
library(skimr)     # quick data summaries
```


## Packages for Part Two

In part two of our analysis, the packages, `broom`, `Matrix`, `tidytext`, `glmnet`, `doParallel`, will be used for tidying model outputs, tying text data, and then prepping our data for penalized regression.

```{r load-packages-2}
library(broom)     # tidy model outputs
library(tidytext)  # tidy text 
library(Matrix)    # for sparce matrix
library(glmnet)    # penalized regression
library(doParallel)# parallel processing
```

# Part one

## Data Pull

We are going to pull in a data set from a repository on `Github` using `readr`'s function `read_csv`. 

```{r pull-wine-ratings}
wine_ratings <- read_csv(
  "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"
)
```

## Data Cleaning

+ See in the data imported correctly and/or see some of the top rows

```{r check-rows}
head(wine_ratings) # check top 5 observations
tail(wine_ratings) # check bottom 5 observations
```

Quick summary of data frame

+ Using `skim()` from the `skimr` package we get a nice overview of our dataframe.
  + We are probably going to have to address the `NA`s(**missing** values in `R`) in the categorical columns: `country`, `designation`, `province`, `region_1`, `region_2`,  `taster_name`, `taster_twitter_handle`, `variety`.
  + Additionally, we could do some type of imputation(fancy way of saying fill in or replace) the `NA` values in the `price` column. 
    + We also see that the our column `points` is normally distributed(good for a linear model), but our column `price` is heavily skewed(might want to transform it).

```{r summarize-df}
skim(wine_ratings) # quickly summarize our data frame
```


Data Cleanup
  
+ Model's don't deal with `NA`s or missing values very well, so:
  + For *categorical*, values we want to replace that `NA` with a character value of **missing** or **unknown**(the absence of information is information).
  + For *numeric* columns, there are loads of options like mean, median imputation or even some more advance techniques that I will talk about at some other time.
+ The `title` column also has some useful information that we will want to extract out of it for instance `year`.

Power of the **Pipe** a code-breakdown

+ The `%>%` or **Pipe** is the logical equivalent to a **then** statement... So, why is the unbelievably awesome?  As humans, we tend to work in a very procedural way, we take `thing` **then** do `other thing`... rinse and repeat
  + we want to create a new object `wine_df` and `<-` assign  `wine_ratings` **then** `%>%`
    + remove `X1` `select()` **then** `%>%`
    + replace our `NA`s `replace_na()` **then** `%>%`
    + pull year out of our `title` column `extract()` **then** `%>%`
    + change any weird `year` to values(3000 bc...) to `NA` with `mutate()` **then** `%>%`
    + remove any observations that don't have a price or points rating `filter()` **then** `%>%`
    + create a unique id column with `mutate()`


```{r process-df}
wine_df <- wine_ratings %>% 
  select(-X1) %>% 
  replace_na(list(country = "missing", province = "missing", taster_name = "missing")) %>% 
  extract(col = title, into = "year", regex = "(\\d\\d\\d\\d)", convert = TRUE, remove = FALSE) %>% 
  mutate(year = ifelse(year > 2020, NA, year),
         year = ifelse(year < 1970, NA, year)) %>% 
  filter(
    !is.na(price),
    !is.na(points),
    !is.na(year),
    year > 1999
  ) %>% 
  mutate(
    wine_id = row_number()
  )
  
```

Boom... data cleaning... pretty much done... almost


# Exploratory Data Analysis

One of `tidyverse`'s/`R`'s best feature is the `ggplot2` package, which stands for the grammar of graphics ...2(the prophet Hadley retire the first iteration).  It allows us to quickly create production level graphs by continuously adding layers. 

![](./imgs/grammar-of-graphics.png)

+ checking distributions
+ extra summary plots

```{r}
# check years
wine_df %>%
    ggplot() + 
    geom_histogram(aes(year), binwidth = 1)

# check dist of points
wine_df %>% 
  ggplot() + 
  geom_histogram(aes(points), binwidth = 1)

# chekc the price distribution
wine_df %>% 
  ggplot() + 
  geom_histogram(aes(price)) +
  scale_x_log10()
```

# Model 

```{r}
# train model
lm_mod <- wine_df %>% 
  mutate(
    country = fct_lump(country, n = 10)
  ) %>% 
  lm(points ~ log2(price) + country + year, data = .) 
```

```{r model-check}
# check coeff
lm_mod %>% 
  tidy(conf.int = TRUE) %>% 
  filter(term != "(Intercept)") %>% 
  mutate(term = fct_reorder(term, estimate)) %>% 
  ggplot() + 
    geom_point(aes(x = term, y = estimate)) + 
    geom_errorbar(aes(x = term, ymin = conf.low, ymax = conf.high)) + 
    coord_flip()

# check model coefs contribution of variance explanation
lm_mod %>% 
  anova() %>% 
  tidy() %>% 
  mutate(
    contribution = sumsq/sum(sumsq)
  )
  
# check predictions
lm_mod %>% 
  augment() %>% 
  ggplot() + 
    geom_point(aes(y = points, x = .fitted), alpha = .1) + 
    geom_abline(color = "red")
```


# Text mining

+ tidy text data
+ most used words
+ which words are good
+ put into matrix form for modeling with glmnet
+ ...

```{r process-text}
# tidy text package
wine_words_df <- wine_df %>%
  unnest_tokens(word, description) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("wine", "drink"),
         str_detect(word, "[a-z]"))

# check df 
wine_words_df
```

check top words

```{r}
wine_words_df %>%
  count(word, sort = TRUE) %>%
  head(20) %>%
  mutate(word = fct_reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip()
```

```{r filter-words}
wine_words_filtered_df <- wine_words_df %>%
  distinct(wine_id, word) %>%
  add_count(word) %>%
  filter(n >= 1000)
```


## which words are good?

 + enter the glmnet

```{r process-matrix}
# matrix package
# put into matrix
wine_word_matrix <- wine_words_filtered_df %>%
  cast_sparse(wine_id, word)

# 
wine_ids <- as.integer(rownames(wine_word_matrix))

# dependent variable
scores <- wine_df$points[wine_ids]

# add back price
wine_word_matrix_extra <- cbind(wine_word_matrix, log_price = log2(wine_words_df$price[wine_ids]))
```


Now let's run a penalized regression

```{r fit-glmnet}
# doparallel package
# glmnet package 

# set up parallel processing
registerDoParallel(4)

# create a cross validated model
glmnet_mod <- cv.glmnet(
    x = wine_word_matrix_extra
  , y = scores
  , family = c("gaussian")
  , parallel = TRUE
)
```

## check glmnet

```{r}
# you can see the impact of lambda on terms coefficients
glmnet_mod$glmnet.fit %>%
  tidy() %>%
  filter(term %in% c("rich", "black", "simple", "complex", "vineyard", "concentrated")) %>%
  ggplot(aes(lambda, estimate, color = term)) +
  geom_line() +
  scale_x_log10() +
  geom_hline(lty = 2, yintercept = 0) + 
  labs(
    title = "Lambda's impact on Coefficients"
  )

# smaller the penalty the more terms in the model
glmnet_mod$glmnet.fit %>%
  tidy() %>%
  count(lambda) %>%
  ggplot(aes(lambda, n)) +
  geom_line() +
  scale_x_log10() + 
  labs(
    title = "As Lambda Increases(Our Penalty) the Number of our Terms Decreases",
    y = "Number of Terms",
    x = "Lambda(Penalty)"
  )

# what's the best lambda
plot(glmnet_mod)
```



## Creating our own lexicon

```{r create-lexicon}
lexicon_df <- glmnet_mod$glmnet.fit %>%
  tidy() %>%
  filter(lambda == glmnet_mod$lambda.1se,
         term != "(Intercept)",
         term != "log_price") %>%
  select(word = term, coefficient = estimate)
```



```{r}
lexicon_df %>%
  arrange(coefficient) %>%
  group_by(direction = ifelse(coefficient < 0, "Negative", "Positive")) %>%
  top_n(16, abs(coefficient)) %>%
  ungroup() %>%
  mutate(word = fct_reorder(word, coefficient)) %>%
  ggplot(aes(word, coefficient, fill = direction)) +
  geom_col() +
  coord_flip() +
  labs(x = "",
       y = "Estimated effect of the word on the score",
       title = "What words are predictive of a wine's score?")
```


```{r}
wine_words_df %>%
  filter(wine_id %in% sample(unique(wine_id), 4)) %>%
  distinct(word, title, points) %>%
  mutate(wine = paste0(str_trunc(title, 40), " (", points, ")")) %>%
  inner_join(lexicon_df, by = "word") %>%
  mutate(word = fct_reorder(word, coefficient)) %>%
  ggplot(aes(word, coefficient, fill = coefficient > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~ wine, scales = "free_y") +
  labs(title = "How a lasso regression would predict each wine's score",
       subtitle = "Using a lasso regression with an extra term for price",
       x = "",
       y = "Effect on score")
```












